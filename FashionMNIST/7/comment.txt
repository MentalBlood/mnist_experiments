Гипотеза:
Увеличение количества сверточных слоев и количества каналов в каждом из них
Уменьшение размеров ядер сверток. Увеличение количества нейронов в первом полносвязном слое
Добавление дропаута и побатчевой нормализации. Добавление "сплющивающего" (flatten) слоя
Замена функций активации (кроме относящейся к последнему слою) на выпрямляющую единицу (ReLU)
Замена функции активации, относящейся к последнему слою, на сигмоидальную
приведет к существенному повышению точности модели на тестовом датасете.
Реализации:
Увеличение количества сверточных слоев до 4. Количество каналов в сверточных слоях: 32, 32, 64, 64. Увеличение количества нейронов в первом полносвязном слое до 128. Добавление дропаута, побатчевой нормализации и "сплющивающего" слоя таким образом, что итоговая модель выглядит так:
...
Результат:
94.01% после 287-ой эпохи (дальнейшее обучение не производилось)