{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет о создании и обучении на датасете Fashion MNIST модели CNN (гипотеза 6, реализация 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "\n",
    "- Список терминов, специфичных для темы отчета\n",
    "- Введение\n",
    "- 1 Создание и обучение модели\n",
    " - 1.1 Загрузка датасета\n",
    " - 1.2 Создание модели\n",
    " - 1.3 Обучение модели\n",
    " - 1.4 Сохранение модели на диск\n",
    "- 2 Рекомендации по дальнейшему улучшению/развитию модели\n",
    "- Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Список терминов, специфичных для темы отчета\n",
    "\n",
    "См. раздел \"Машинное обучение\" документа \"Словарь терминов, специфичных для выполняемых работ и изучаемых материалов в период с 25 сентября 2020 г. по 25 ноября 2020 г.\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В настоящем отчете приведен код, соответствующий созданию и обучению модели CNN на датасете Fashion MNIST, а также рекомендации по дальнейшему улучшению/развитию модели. Используемый язык программирования – Python. Для создания и обучения модели используются библиотеки MXNet и Gluon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Создание и обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортирование необходимых модулей и функций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet.optimizer import Adam\n",
    "from mxnet import gluon, autograd\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установка вычислительного контекста (для использования при обучении видеокарты, если это возможно):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: [gpu(0)]\n"
     ]
    }
   ],
   "source": [
    "ctx = [mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()]\n",
    "print('context:', ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Загрузка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка датасета и установка размера батча равным 128:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "mnist_train = datasets.FashionMNIST(train=True)\n",
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.13, 0.31)])\n",
    "mnist_train = mnist_train.transform_first(transformer)\n",
    "train_data = gluon.data.DataLoader(\n",
    "    mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "mnist_valid = gluon.data.vision.FashionMNIST(train=False)\n",
    "val_data = gluon.data.DataLoader(\n",
    "    mnist_valid.transform_first(transformer),\n",
    "    batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Создание модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание модели, состоящей из 4 слоев:\n",
    "1. Сверточный слой с параметрами:\n",
    "\t- Количество каналов: 8\n",
    "\t- Размер ядра свертки: 4х4\n",
    "\t- Функция активации: гиперболический тангенс\n",
    "2. Слой пулинга с параметрами:\n",
    "\t- Размер ядра пулинга: 2х2\n",
    "\t- Шаг: 2\n",
    "3. Полносвязный слой с параметрами:\n",
    "\t- Количество нейронов: 16\n",
    "\t- Функция активации: гиперболический тангенс\n",
    "4. Полносвязный слой с параметрами:\n",
    "\t- Количество нейронов: 10\n",
    "\t- Функция активации: гиперболический тангенс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.HybridSequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Conv2D   (channels=8, kernel_size=4, activation='tanh'))\n",
    "    net.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    net.add(nn.Dense    (16, activation='tanh'))\n",
    "    net.add(nn.Dense    (10, activation='tanh'))\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для инициализации сети используется метод Завьера (Xavier). В качестве функции потерь используется SCE (Softmax Cross-Entropy loss). В качестве оптимизатора используется Adam (Adaptive Moment Estimation – метод Адаптивной Оценки Моментов). Обучение производится на протижение 100 эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochsForTraining = 150\n",
    "#                   ^^^--- 100 -> 150\n",
    "validationAccToTrain = 0.90\n",
    "\n",
    "def test(ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for data, label in val_data:\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        metric.update([label], [output])\n",
    "\n",
    "    return metric.get()\n",
    "\n",
    "def train(net, ctx):\n",
    "    # Collect all parameters from net and its children, then initialize them.\n",
    "    net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "    # Trainer is for updating parameters with gradient.\n",
    "    trainer = gluon.Trainer(net.collect_params(), Adam())\n",
    "    metric = mx.metric.Accuracy()\n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    maxValidationAcc = 0\n",
    "    for i in range(epochsForTraining):\n",
    "        # reset data iterator and metric at begining of epoch.\n",
    "        metric.reset()\n",
    "        for j, (data, label) in enumerate(train_data):\n",
    "            # Copy data to ctx if necessary\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            # Start recording computation graph with record() section.\n",
    "            # Recorded graphs can then be differentiated with backward.\n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                L = loss(output, label)\n",
    "                L.backward()\n",
    "            # take a gradient step with batch_size equal to data.shape[0]\n",
    "            trainer.step(data.shape[0])\n",
    "            # update metric at last.\n",
    "            metric.update([label], [output])\n",
    "\n",
    "        name, acc = metric.get()\n",
    "        name, validationAcc = test(ctx)\n",
    "        epoch = i + 1\n",
    "        print('epoch', ('{:2.0f}:').format(epoch), '\\t', \"{:.2f}%\".format(acc * 100), '- train set accuracy'\n",
    "              '\\n\\t\\t', \"{:.2f}%\".format(validationAcc * 100), '- validation set accuracy')\n",
    "        if validationAcc > maxValidationAcc:\n",
    "            maxValidationAcc = validationAcc\n",
    "            if validationAcc >= validationAccToTrain:\n",
    "                net.export('exported/150/fashion_mnist', epoch=epoch)\n",
    "                print('saved epoch', epoch)\n",
    "        print()\n",
    "    print('Best result: {:.2f}%'.format(maxValidationAcc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1: \t 77.08% - train set accuracy\n",
      "\t\t 82.60% - validation set accuracy\n",
      "\n",
      "epoch  2: \t 83.91% - train set accuracy\n",
      "\t\t 85.34% - validation set accuracy\n",
      "\n",
      "epoch  3: \t 85.86% - train set accuracy\n",
      "\t\t 86.31% - validation set accuracy\n",
      "\n",
      "epoch  4: \t 86.92% - train set accuracy\n",
      "\t\t 87.35% - validation set accuracy\n",
      "\n",
      "epoch  5: \t 87.41% - train set accuracy\n",
      "\t\t 86.98% - validation set accuracy\n",
      "\n",
      "epoch  6: \t 87.83% - train set accuracy\n",
      "\t\t 87.62% - validation set accuracy\n",
      "\n",
      "epoch  7: \t 88.20% - train set accuracy\n",
      "\t\t 88.44% - validation set accuracy\n",
      "\n",
      "epoch  8: \t 88.34% - train set accuracy\n",
      "\t\t 88.58% - validation set accuracy\n",
      "\n",
      "epoch  9: \t 88.69% - train set accuracy\n",
      "\t\t 87.83% - validation set accuracy\n",
      "\n",
      "epoch 10: \t 88.96% - train set accuracy\n",
      "\t\t 88.72% - validation set accuracy\n",
      "\n",
      "epoch 11: \t 89.18% - train set accuracy\n",
      "\t\t 88.56% - validation set accuracy\n",
      "\n",
      "epoch 12: \t 89.27% - train set accuracy\n",
      "\t\t 88.60% - validation set accuracy\n",
      "\n",
      "epoch 13: \t 89.51% - train set accuracy\n",
      "\t\t 88.39% - validation set accuracy\n",
      "\n",
      "epoch 14: \t 89.71% - train set accuracy\n",
      "\t\t 88.94% - validation set accuracy\n",
      "\n",
      "epoch 15: \t 89.79% - train set accuracy\n",
      "\t\t 88.61% - validation set accuracy\n",
      "\n",
      "epoch 16: \t 89.88% - train set accuracy\n",
      "\t\t 89.04% - validation set accuracy\n",
      "\n",
      "epoch 17: \t 90.17% - train set accuracy\n",
      "\t\t 88.96% - validation set accuracy\n",
      "\n",
      "epoch 18: \t 90.09% - train set accuracy\n",
      "\t\t 88.95% - validation set accuracy\n",
      "\n",
      "epoch 19: \t 90.20% - train set accuracy\n",
      "\t\t 89.02% - validation set accuracy\n",
      "\n",
      "epoch 20: \t 90.31% - train set accuracy\n",
      "\t\t 89.04% - validation set accuracy\n",
      "\n",
      "epoch 21: \t 90.56% - train set accuracy\n",
      "\t\t 89.28% - validation set accuracy\n",
      "\n",
      "epoch 22: \t 90.55% - train set accuracy\n",
      "\t\t 89.42% - validation set accuracy\n",
      "\n",
      "epoch 23: \t 90.67% - train set accuracy\n",
      "\t\t 89.67% - validation set accuracy\n",
      "\n",
      "epoch 24: \t 90.61% - train set accuracy\n",
      "\t\t 89.16% - validation set accuracy\n",
      "\n",
      "epoch 25: \t 90.76% - train set accuracy\n",
      "\t\t 89.63% - validation set accuracy\n",
      "\n",
      "epoch 26: \t 90.81% - train set accuracy\n",
      "\t\t 89.41% - validation set accuracy\n",
      "\n",
      "epoch 27: \t 90.87% - train set accuracy\n",
      "\t\t 89.31% - validation set accuracy\n",
      "\n",
      "epoch 28: \t 91.05% - train set accuracy\n",
      "\t\t 89.57% - validation set accuracy\n",
      "\n",
      "epoch 29: \t 91.10% - train set accuracy\n",
      "\t\t 89.34% - validation set accuracy\n",
      "\n",
      "epoch 30: \t 90.98% - train set accuracy\n",
      "\t\t 89.68% - validation set accuracy\n",
      "\n",
      "epoch 31: \t 91.05% - train set accuracy\n",
      "\t\t 89.62% - validation set accuracy\n",
      "\n",
      "epoch 32: \t 91.12% - train set accuracy\n",
      "\t\t 89.63% - validation set accuracy\n",
      "\n",
      "epoch 33: \t 91.21% - train set accuracy\n",
      "\t\t 89.43% - validation set accuracy\n",
      "\n",
      "epoch 34: \t 91.23% - train set accuracy\n",
      "\t\t 89.17% - validation set accuracy\n",
      "\n",
      "epoch 35: \t 91.29% - train set accuracy\n",
      "\t\t 89.49% - validation set accuracy\n",
      "\n",
      "epoch 36: \t 91.38% - train set accuracy\n",
      "\t\t 89.26% - validation set accuracy\n",
      "\n",
      "epoch 37: \t 91.42% - train set accuracy\n",
      "\t\t 89.29% - validation set accuracy\n",
      "\n",
      "epoch 38: \t 91.36% - train set accuracy\n",
      "\t\t 89.33% - validation set accuracy\n",
      "\n",
      "epoch 39: \t 91.48% - train set accuracy\n",
      "\t\t 89.67% - validation set accuracy\n",
      "\n",
      "epoch 40: \t 91.69% - train set accuracy\n",
      "\t\t 89.14% - validation set accuracy\n",
      "\n",
      "epoch 41: \t 91.57% - train set accuracy\n",
      "\t\t 89.64% - validation set accuracy\n",
      "\n",
      "epoch 42: \t 91.69% - train set accuracy\n",
      "\t\t 89.65% - validation set accuracy\n",
      "\n",
      "epoch 43: \t 91.59% - train set accuracy\n",
      "\t\t 89.64% - validation set accuracy\n",
      "\n",
      "epoch 44: \t 91.68% - train set accuracy\n",
      "\t\t 89.35% - validation set accuracy\n",
      "\n",
      "epoch 45: \t 91.64% - train set accuracy\n",
      "\t\t 89.25% - validation set accuracy\n",
      "\n",
      "epoch 46: \t 91.76% - train set accuracy\n",
      "\t\t 89.52% - validation set accuracy\n",
      "\n",
      "epoch 47: \t 91.86% - train set accuracy\n",
      "\t\t 89.40% - validation set accuracy\n",
      "\n",
      "epoch 48: \t 91.77% - train set accuracy\n",
      "\t\t 89.02% - validation set accuracy\n",
      "\n",
      "epoch 49: \t 91.81% - train set accuracy\n",
      "\t\t 89.51% - validation set accuracy\n",
      "\n",
      "epoch 50: \t 91.77% - train set accuracy\n",
      "\t\t 89.55% - validation set accuracy\n",
      "\n",
      "epoch 51: \t 91.96% - train set accuracy\n",
      "\t\t 89.44% - validation set accuracy\n",
      "\n",
      "epoch 52: \t 92.01% - train set accuracy\n",
      "\t\t 89.35% - validation set accuracy\n",
      "\n",
      "epoch 53: \t 91.98% - train set accuracy\n",
      "\t\t 89.60% - validation set accuracy\n",
      "\n",
      "epoch 54: \t 92.03% - train set accuracy\n",
      "\t\t 89.50% - validation set accuracy\n",
      "\n",
      "epoch 55: \t 92.04% - train set accuracy\n",
      "\t\t 89.63% - validation set accuracy\n",
      "\n",
      "epoch 56: \t 92.17% - train set accuracy\n",
      "\t\t 89.43% - validation set accuracy\n",
      "\n",
      "epoch 57: \t 92.17% - train set accuracy\n",
      "\t\t 89.40% - validation set accuracy\n",
      "\n",
      "epoch 58: \t 92.12% - train set accuracy\n",
      "\t\t 89.53% - validation set accuracy\n",
      "\n",
      "epoch 59: \t 92.24% - train set accuracy\n",
      "\t\t 89.50% - validation set accuracy\n",
      "\n",
      "epoch 60: \t 92.22% - train set accuracy\n",
      "\t\t 89.53% - validation set accuracy\n",
      "\n",
      "epoch 61: \t 92.15% - train set accuracy\n",
      "\t\t 89.48% - validation set accuracy\n",
      "\n",
      "epoch 62: \t 92.18% - train set accuracy\n",
      "\t\t 89.57% - validation set accuracy\n",
      "\n",
      "epoch 63: \t 92.25% - train set accuracy\n",
      "\t\t 89.49% - validation set accuracy\n",
      "\n",
      "epoch 64: \t 92.28% - train set accuracy\n",
      "\t\t 89.26% - validation set accuracy\n",
      "\n",
      "epoch 65: \t 92.44% - train set accuracy\n",
      "\t\t 89.41% - validation set accuracy\n",
      "\n",
      "epoch 66: \t 92.36% - train set accuracy\n",
      "\t\t 89.27% - validation set accuracy\n",
      "\n",
      "epoch 67: \t 92.30% - train set accuracy\n",
      "\t\t 89.43% - validation set accuracy\n",
      "\n",
      "epoch 68: \t 92.38% - train set accuracy\n",
      "\t\t 89.56% - validation set accuracy\n",
      "\n",
      "epoch 69: \t 92.41% - train set accuracy\n",
      "\t\t 89.48% - validation set accuracy\n",
      "\n",
      "epoch 70: \t 92.44% - train set accuracy\n",
      "\t\t 89.34% - validation set accuracy\n",
      "\n",
      "epoch 71: \t 92.39% - train set accuracy\n",
      "\t\t 89.06% - validation set accuracy\n",
      "\n",
      "epoch 72: \t 92.48% - train set accuracy\n",
      "\t\t 89.51% - validation set accuracy\n",
      "\n",
      "epoch 73: \t 92.55% - train set accuracy\n",
      "\t\t 89.19% - validation set accuracy\n",
      "\n",
      "epoch 74: \t 92.44% - train set accuracy\n",
      "\t\t 89.12% - validation set accuracy\n",
      "\n",
      "epoch 75: \t 92.47% - train set accuracy\n",
      "\t\t 89.41% - validation set accuracy\n",
      "\n",
      "epoch 76: \t 92.59% - train set accuracy\n",
      "\t\t 89.46% - validation set accuracy\n",
      "\n",
      "epoch 77: \t 92.58% - train set accuracy\n",
      "\t\t 89.29% - validation set accuracy\n",
      "\n",
      "epoch 78: \t 92.70% - train set accuracy\n",
      "\t\t 89.24% - validation set accuracy\n",
      "\n",
      "epoch 79: \t 92.56% - train set accuracy\n",
      "\t\t 89.71% - validation set accuracy\n",
      "\n",
      "epoch 80: \t 92.58% - train set accuracy\n",
      "\t\t 89.25% - validation set accuracy\n",
      "\n",
      "epoch 81: \t 92.62% - train set accuracy\n",
      "\t\t 89.82% - validation set accuracy\n",
      "\n",
      "epoch 82: \t 92.57% - train set accuracy\n",
      "\t\t 89.18% - validation set accuracy\n",
      "\n",
      "epoch 83: \t 92.65% - train set accuracy\n",
      "\t\t 89.45% - validation set accuracy\n",
      "\n",
      "epoch 84: \t 92.75% - train set accuracy\n",
      "\t\t 89.57% - validation set accuracy\n",
      "\n",
      "epoch 85: \t 92.75% - train set accuracy\n",
      "\t\t 89.53% - validation set accuracy\n",
      "\n",
      "epoch 86: \t 92.71% - train set accuracy\n",
      "\t\t 89.53% - validation set accuracy\n",
      "\n",
      "epoch 87: \t 92.73% - train set accuracy\n",
      "\t\t 89.62% - validation set accuracy\n",
      "\n",
      "epoch 88: \t 92.70% - train set accuracy\n",
      "\t\t 89.46% - validation set accuracy\n",
      "\n",
      "epoch 89: \t 92.71% - train set accuracy\n",
      "\t\t 89.10% - validation set accuracy\n",
      "\n",
      "epoch 90: \t 92.81% - train set accuracy\n",
      "\t\t 89.57% - validation set accuracy\n",
      "\n",
      "epoch 91: \t 92.79% - train set accuracy\n",
      "\t\t 89.46% - validation set accuracy\n",
      "\n",
      "epoch 92: \t 92.71% - train set accuracy\n",
      "\t\t 89.38% - validation set accuracy\n",
      "\n",
      "epoch 93: \t 92.77% - train set accuracy\n",
      "\t\t 89.44% - validation set accuracy\n",
      "\n",
      "epoch 94: \t 92.81% - train set accuracy\n",
      "\t\t 89.42% - validation set accuracy\n",
      "\n",
      "epoch 95: \t 92.86% - train set accuracy\n",
      "\t\t 89.20% - validation set accuracy\n",
      "\n",
      "epoch 96: \t 92.76% - train set accuracy\n",
      "\t\t 89.32% - validation set accuracy\n",
      "\n",
      "epoch 97: \t 92.91% - train set accuracy\n",
      "\t\t 89.13% - validation set accuracy\n",
      "\n",
      "epoch 98: \t 92.93% - train set accuracy\n",
      "\t\t 89.51% - validation set accuracy\n",
      "\n",
      "epoch 99: \t 92.90% - train set accuracy\n",
      "\t\t 89.37% - validation set accuracy\n",
      "\n",
      "epoch 100: \t 92.95% - train set accuracy\n",
      "\t\t 89.41% - validation set accuracy\n",
      "\n",
      "epoch 101: \t 92.91% - train set accuracy\n",
      "\t\t 89.60% - validation set accuracy\n",
      "\n",
      "epoch 102: \t 93.03% - train set accuracy\n",
      "\t\t 89.37% - validation set accuracy\n",
      "\n",
      "epoch 103: \t 92.94% - train set accuracy\n",
      "\t\t 89.21% - validation set accuracy\n",
      "\n",
      "epoch 104: \t 92.99% - train set accuracy\n",
      "\t\t 89.25% - validation set accuracy\n",
      "\n",
      "epoch 105: \t 93.01% - train set accuracy\n",
      "\t\t 89.53% - validation set accuracy\n",
      "\n",
      "epoch 106: \t 93.00% - train set accuracy\n",
      "\t\t 89.34% - validation set accuracy\n",
      "\n",
      "epoch 107: \t 93.00% - train set accuracy\n",
      "\t\t 89.59% - validation set accuracy\n",
      "\n",
      "epoch 108: \t 93.14% - train set accuracy\n",
      "\t\t 89.49% - validation set accuracy\n",
      "\n",
      "epoch 109: \t 93.00% - train set accuracy\n",
      "\t\t 89.66% - validation set accuracy\n",
      "\n",
      "epoch 110: \t 93.13% - train set accuracy\n",
      "\t\t 89.24% - validation set accuracy\n",
      "\n",
      "epoch 111: \t 93.03% - train set accuracy\n",
      "\t\t 89.43% - validation set accuracy\n",
      "\n",
      "epoch 112: \t 93.08% - train set accuracy\n",
      "\t\t 89.40% - validation set accuracy\n",
      "\n",
      "epoch 113: \t 93.14% - train set accuracy\n",
      "\t\t 89.33% - validation set accuracy\n",
      "\n",
      "epoch 114: \t 93.12% - train set accuracy\n",
      "\t\t 89.35% - validation set accuracy\n",
      "\n",
      "epoch 115: \t 93.15% - train set accuracy\n",
      "\t\t 89.42% - validation set accuracy\n",
      "\n",
      "epoch 116: \t 93.15% - train set accuracy\n",
      "\t\t 89.20% - validation set accuracy\n",
      "\n",
      "epoch 117: \t 93.05% - train set accuracy\n",
      "\t\t 89.16% - validation set accuracy\n",
      "\n",
      "epoch 118: \t 93.15% - train set accuracy\n",
      "\t\t 89.36% - validation set accuracy\n",
      "\n",
      "epoch 119: \t 93.07% - train set accuracy\n",
      "\t\t 88.91% - validation set accuracy\n",
      "\n",
      "epoch 120: \t 93.27% - train set accuracy\n",
      "\t\t 89.09% - validation set accuracy\n",
      "\n",
      "epoch 121: \t 93.12% - train set accuracy\n",
      "\t\t 89.15% - validation set accuracy\n",
      "\n",
      "epoch 122: \t 93.19% - train set accuracy\n",
      "\t\t 89.15% - validation set accuracy\n",
      "\n",
      "epoch 123: \t 93.24% - train set accuracy\n",
      "\t\t 88.99% - validation set accuracy\n",
      "\n",
      "epoch 124: \t 93.09% - train set accuracy\n",
      "\t\t 88.81% - validation set accuracy\n",
      "\n",
      "epoch 125: \t 93.16% - train set accuracy\n",
      "\t\t 89.46% - validation set accuracy\n",
      "\n",
      "epoch 126: \t 93.20% - train set accuracy\n",
      "\t\t 89.34% - validation set accuracy\n",
      "\n",
      "epoch 127: \t 93.23% - train set accuracy\n",
      "\t\t 89.17% - validation set accuracy\n",
      "\n",
      "epoch 128: \t 93.31% - train set accuracy\n",
      "\t\t 89.44% - validation set accuracy\n",
      "\n",
      "epoch 129: \t 93.23% - train set accuracy\n",
      "\t\t 89.16% - validation set accuracy\n",
      "\n",
      "epoch 130: \t 93.24% - train set accuracy\n",
      "\t\t 89.45% - validation set accuracy\n",
      "\n",
      "epoch 131: \t 93.32% - train set accuracy\n",
      "\t\t 89.20% - validation set accuracy\n",
      "\n",
      "epoch 132: \t 93.35% - train set accuracy\n",
      "\t\t 89.32% - validation set accuracy\n",
      "\n",
      "epoch 133: \t 93.14% - train set accuracy\n",
      "\t\t 89.34% - validation set accuracy\n",
      "\n",
      "epoch 134: \t 93.34% - train set accuracy\n",
      "\t\t 89.25% - validation set accuracy\n",
      "\n",
      "epoch 135: \t 93.33% - train set accuracy\n",
      "\t\t 89.04% - validation set accuracy\n",
      "\n",
      "epoch 136: \t 93.34% - train set accuracy\n",
      "\t\t 89.61% - validation set accuracy\n",
      "\n",
      "epoch 137: \t 93.39% - train set accuracy\n",
      "\t\t 89.30% - validation set accuracy\n",
      "\n",
      "epoch 138: \t 93.31% - train set accuracy\n",
      "\t\t 89.35% - validation set accuracy\n",
      "\n",
      "epoch 139: \t 93.34% - train set accuracy\n",
      "\t\t 89.38% - validation set accuracy\n",
      "\n",
      "epoch 140: \t 93.38% - train set accuracy\n",
      "\t\t 89.56% - validation set accuracy\n",
      "\n",
      "epoch 141: \t 93.35% - train set accuracy\n",
      "\t\t 89.24% - validation set accuracy\n",
      "\n",
      "epoch 142: \t 93.42% - train set accuracy\n",
      "\t\t 89.17% - validation set accuracy\n",
      "\n",
      "epoch 143: \t 93.28% - train set accuracy\n",
      "\t\t 89.25% - validation set accuracy\n",
      "\n",
      "epoch 144: \t 93.31% - train set accuracy\n",
      "\t\t 89.21% - validation set accuracy\n",
      "\n",
      "epoch 145: \t 93.33% - train set accuracy\n",
      "\t\t 89.29% - validation set accuracy\n",
      "\n",
      "epoch 146: \t 93.50% - train set accuracy\n",
      "\t\t 89.17% - validation set accuracy\n",
      "\n",
      "epoch 147: \t 93.48% - train set accuracy\n",
      "\t\t 89.28% - validation set accuracy\n",
      "\n",
      "epoch 148: \t 93.36% - train set accuracy\n",
      "\t\t 88.99% - validation set accuracy\n",
      "\n",
      "epoch 149: \t 93.40% - train set accuracy\n",
      "\t\t 89.14% - validation set accuracy\n",
      "\n",
      "epoch 150: \t 93.40% - train set accuracy\n",
      "\t\t 89.33% - validation set accuracy\n",
      "\n",
      "Best result: 89.82%\n"
     ]
    }
   ],
   "source": [
    "train(net, ctx[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная достигнутая точность на проверочной части датасета составляет **89.82%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Сохранение модели на диск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели выполняется посредством функции `train` (см. раздел 1.3). Функция `train` использует глобальные переменные `validationAccToTrain` и `epochsForTraining`. Значение глобальной переменной `validationAccToTrain` соответствует точности (accuracy) на проверочной части датасета, при достижении которой и одновременно максимальной точности в ходе обучения, необходимо сохранить архитектуру и параметры модели на диск. Сохранение модели на диск выполняется посредством функции `net.export`, при этом создаются/перезаписываются два файла: **fashion-mnist-symbol.json**, содержащий информацию, определяющую архитектуру модели, и **fashion-mnist-<номер эпохи>.params**, содержащий параметры модели, полученные в ходе обучения и соответствующие эпохе <номер эпохи>. Значение глобальной переменной `epochsForTraining` соответствует количеству эпох, в течение которых необходимо проводить обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Официальный сайт mxnet: https://mxnet.apache.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
