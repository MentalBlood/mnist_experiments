{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет о создании и обучении на датасете MNIST модели CNN (гипотеза 6, реализация 4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "\n",
    "- Список терминов, специфичных для темы отчета\n",
    "- Введение\n",
    "- 1 Создание и обучение модели\n",
    " - 1.1 Загрузка датасета\n",
    " - 1.2 Создание модели\n",
    " - 1.3 Обучение модели\n",
    " - 1.4 Сохранение модели на диск\n",
    "- 2 Рекомендации по дальнейшему улучшению/развитию модели\n",
    "- Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Список терминов, специфичных для темы отчета\n",
    "\n",
    "См. раздел \"Машинное обучение\" документа \"Словарь терминов, специфичных для выполняемых работ и изучаемых материалов в период с 25 сентября 2020 г. по 25 ноября 2020 г.\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В настоящем отчете приведен код, соответствующий созданию и обучению модели CNN на датасете MNIST, а также рекомендации по дальнейшему улучшению/развитию модели. Используемый язык программирования – Python. Для создания и обучения модели используются библиотеки MXNet и Gluon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Создание и обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортирование необходимых модулей и функций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet.optimizer import Adam\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd as ag\n",
    "from mxnet import gluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установка вычислительного контекста (для использования при обучении видеокарты, если это возможно):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: [gpu(0)]\n"
     ]
    }
   ],
   "source": [
    "ctx = [mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()]\n",
    "print('context:', ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Загрузка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка датасета и установка размера батча равным 200:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mx.test_utils.get_mnist()\n",
    "\n",
    "batch_size = 200\n",
    "train_data = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True)\n",
    "val_data = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Создание модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание модели, состоящей из 6 слоев:\n",
    "1. Сверточный слой с параметрами:\n",
    "\t- Количество каналов: 10\n",
    "\t- Размер ядра свертки: 5х5\n",
    "\t- Функция активации: гиперболический тангенс\n",
    "2. Слой пулинга с параметрами:\n",
    "\t- Размер ядра пулинга: 2х2\n",
    "\t- Шаг: 2\n",
    "3. Сверточный слой\n",
    "\t- Количество каналов: 25\n",
    "\t- Размер ядра свертки: 5х5\n",
    "\t- Функция активации: гиперболический тангенс\n",
    "4. Слой пулинга с параметрами:\n",
    "\t- Размер ядра пулинга: 2х2\n",
    "\t- Шаг: 2\n",
    "5. Полносвязный слой с параметрами:\n",
    "\t- Количество нейронов: 20\n",
    "\t- Функция активации: гиперболический тангенс\n",
    "6. Полносвязный слой с параметрами:\n",
    "\t- Количество нейронов: 10\n",
    "\t- Функция активации: гиперболический тангенс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.HybridSequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Conv2D(10, kernel_size=5, activation='tanh'))\n",
    "    net.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    net.add(nn.Conv2D(25, kernel_size=5, activation='tanh'))\n",
    "    net.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    net.add(nn.Dense(20, activation='tanh'))\n",
    "    net.add(nn.Dense(10, activation='tanh'))\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для инициализации сети используется метод Завьера (Xavier). В качестве функции потерь используется SCE (Softmax Cross-Entropy loss). В качестве оптимизатора используется градиентный спуск с инерцией. Темп обучения (learning rate) устанавливается равным 0.6. Обучение производится в течение **300** эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1: \t 90.41% - train set accuracy\n",
      "\t\t 97.17% - validation set accuracy\n",
      "\n",
      "epoch  2: \t 97.30% - train set accuracy\n",
      "\t\t 98.05% - validation set accuracy\n",
      "\n",
      "epoch  3: \t 98.02% - train set accuracy\n",
      "\t\t 98.16% - validation set accuracy\n",
      "\n",
      "epoch  4: \t 98.38% - train set accuracy\n",
      "\t\t 98.29% - validation set accuracy\n",
      "\n",
      "epoch  5: \t 98.57% - train set accuracy\n",
      "\t\t 98.54% - validation set accuracy\n",
      "\n",
      "epoch  6: \t 98.74% - train set accuracy\n",
      "\t\t 98.57% - validation set accuracy\n",
      "\n",
      "epoch  7: \t 98.95% - train set accuracy\n",
      "\t\t 98.61% - validation set accuracy\n",
      "\n",
      "epoch  8: \t 99.03% - train set accuracy\n",
      "\t\t 98.61% - validation set accuracy\n",
      "\n",
      "epoch  9: \t 99.14% - train set accuracy\n",
      "\t\t 98.62% - validation set accuracy\n",
      "\n",
      "epoch 10: \t 99.22% - train set accuracy\n",
      "\t\t 98.74% - validation set accuracy\n",
      "\n",
      "epoch 11: \t 99.26% - train set accuracy\n",
      "\t\t 98.70% - validation set accuracy\n",
      "\n",
      "epoch 12: \t 99.33% - train set accuracy\n",
      "\t\t 98.79% - validation set accuracy\n",
      "\n",
      "epoch 13: \t 99.35% - train set accuracy\n",
      "\t\t 98.70% - validation set accuracy\n",
      "\n",
      "epoch 14: \t 99.44% - train set accuracy\n",
      "\t\t 98.86% - validation set accuracy\n",
      "\n",
      "epoch 15: \t 99.45% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 16: \t 99.50% - train set accuracy\n",
      "\t\t 98.84% - validation set accuracy\n",
      "\n",
      "epoch 17: \t 99.52% - train set accuracy\n",
      "\t\t 98.88% - validation set accuracy\n",
      "\n",
      "epoch 18: \t 99.56% - train set accuracy\n",
      "\t\t 98.89% - validation set accuracy\n",
      "\n",
      "epoch 19: \t 99.57% - train set accuracy\n",
      "\t\t 98.88% - validation set accuracy\n",
      "\n",
      "epoch 20: \t 99.61% - train set accuracy\n",
      "\t\t 98.77% - validation set accuracy\n",
      "\n",
      "epoch 21: \t 99.63% - train set accuracy\n",
      "\t\t 98.91% - validation set accuracy\n",
      "\n",
      "epoch 22: \t 99.64% - train set accuracy\n",
      "\t\t 98.82% - validation set accuracy\n",
      "\n",
      "epoch 23: \t 99.66% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 24: \t 99.67% - train set accuracy\n",
      "\t\t 98.90% - validation set accuracy\n",
      "\n",
      "epoch 25: \t 99.68% - train set accuracy\n",
      "\t\t 98.87% - validation set accuracy\n",
      "\n",
      "epoch 26: \t 99.69% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 27: \t 99.71% - train set accuracy\n",
      "\t\t 98.91% - validation set accuracy\n",
      "\n",
      "epoch 28: \t 99.72% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 29: \t 99.73% - train set accuracy\n",
      "\t\t 98.87% - validation set accuracy\n",
      "\n",
      "epoch 30: \t 99.74% - train set accuracy\n",
      "\t\t 98.91% - validation set accuracy\n",
      "\n",
      "epoch 31: \t 99.74% - train set accuracy\n",
      "\t\t 98.89% - validation set accuracy\n",
      "\n",
      "epoch 32: \t 99.74% - train set accuracy\n",
      "\t\t 98.90% - validation set accuracy\n",
      "\n",
      "epoch 33: \t 99.75% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 34: \t 99.76% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 35: \t 99.75% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 36: \t 99.76% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 37: \t 99.77% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 38: \t 99.77% - train set accuracy\n",
      "\t\t 98.86% - validation set accuracy\n",
      "\n",
      "epoch 39: \t 99.78% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 40: \t 99.77% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 41: \t 99.77% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 42: \t 99.78% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 43: \t 99.78% - train set accuracy\n",
      "\t\t 98.89% - validation set accuracy\n",
      "\n",
      "epoch 44: \t 99.79% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 45: \t 99.78% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 46: \t 99.78% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 47: \t 99.79% - train set accuracy\n",
      "\t\t 98.90% - validation set accuracy\n",
      "\n",
      "epoch 48: \t 99.79% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 49: \t 99.79% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 50: \t 99.80% - train set accuracy\n",
      "\t\t 98.91% - validation set accuracy\n",
      "\n",
      "epoch 51: \t 99.79% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 52: \t 99.79% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 53: \t 99.80% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 54: \t 99.80% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 55: \t 99.80% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 56: \t 99.80% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 57: \t 99.80% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 58: \t 99.80% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 59: \t 99.80% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 60: \t 99.80% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 61: \t 99.81% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 62: \t 99.81% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 63: \t 99.81% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 64: \t 99.81% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 65: \t 99.81% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 66: \t 99.82% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 67: \t 99.81% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 68: \t 99.81% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 69: \t 99.81% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 70: \t 99.81% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 71: \t 99.81% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 72: \t 99.82% - train set accuracy\n",
      "\t\t 98.90% - validation set accuracy\n",
      "\n",
      "epoch 73: \t 99.82% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 74: \t 99.82% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 75: \t 99.82% - train set accuracy\n",
      "\t\t 98.91% - validation set accuracy\n",
      "\n",
      "epoch 76: \t 99.82% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 77: \t 99.82% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 78: \t 99.82% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 79: \t 99.82% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 80: \t 99.82% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 81: \t 99.82% - train set accuracy\n",
      "\t\t 98.90% - validation set accuracy\n",
      "\n",
      "epoch 82: \t 99.82% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 83: \t 99.83% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 84: \t 99.82% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 85: \t 99.83% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 86: \t 99.83% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 87: \t 99.83% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 88: \t 99.82% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 89: \t 99.83% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 90: \t 99.83% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 91: \t 99.83% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 92: \t 99.83% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 93: \t 99.83% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 94: \t 99.83% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 95: \t 99.83% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 96: \t 99.84% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 97: \t 99.83% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 98: \t 99.84% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 99: \t 99.84% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 100: \t 99.84% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 101: \t 99.84% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 102: \t 99.84% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 103: \t 99.84% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 104: \t 99.83% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 105: \t 99.84% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 106: \t 99.84% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 107: \t 99.84% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 108: \t 99.84% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 109: \t 99.84% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 110: \t 99.84% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 111: \t 99.84% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 112: \t 99.84% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 113: \t 99.84% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 114: \t 99.84% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 115: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 116: \t 99.84% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 117: \t 99.84% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 118: \t 99.85% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 119: \t 99.84% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 120: \t 99.85% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 121: \t 99.84% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 122: \t 99.84% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 123: \t 99.84% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 124: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 125: \t 99.84% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 126: \t 99.84% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 127: \t 99.85% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 128: \t 99.84% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 129: \t 99.84% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 130: \t 99.84% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 131: \t 99.84% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 132: \t 99.85% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 133: \t 99.85% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 134: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 135: \t 99.84% - train set accuracy\n",
      "\t\t 98.92% - validation set accuracy\n",
      "\n",
      "epoch 136: \t 99.85% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 137: \t 99.85% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 138: \t 99.85% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 139: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 140: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 141: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 142: \t 99.85% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 143: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 144: \t 99.85% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 145: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 146: \t 99.85% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 147: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 148: \t 99.85% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 149: \t 99.84% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 150: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 151: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 152: \t 99.84% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 153: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 154: \t 99.84% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 155: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 156: \t 99.85% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 157: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 158: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 159: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 160: \t 99.85% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 161: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 162: \t 99.85% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 163: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 164: \t 99.85% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 165: \t 99.85% - train set accuracy\n",
      "\t\t 99.00% - validation set accuracy\n",
      "saved epoch 165\n",
      "\n",
      "epoch 166: \t 99.85% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 167: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 168: \t 99.85% - train set accuracy\n",
      "\t\t 99.00% - validation set accuracy\n",
      "\n",
      "epoch 169: \t 99.85% - train set accuracy\n",
      "\t\t 99.00% - validation set accuracy\n",
      "\n",
      "epoch 170: \t 99.85% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 171: \t 99.85% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 172: \t 99.85% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 173: \t 99.85% - train set accuracy\n",
      "\t\t 99.01% - validation set accuracy\n",
      "saved epoch 173\n",
      "\n",
      "epoch 174: \t 99.85% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 175: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 176: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 177: \t 99.85% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 178: \t 99.85% - train set accuracy\n",
      "\t\t 99.00% - validation set accuracy\n",
      "\n",
      "epoch 179: \t 99.86% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 180: \t 99.85% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 181: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 182: \t 99.85% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 183: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 184: \t 99.86% - train set accuracy\n",
      "\t\t 99.02% - validation set accuracy\n",
      "saved epoch 184\n",
      "\n",
      "epoch 185: \t 99.86% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 186: \t 99.86% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 187: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 188: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 189: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 190: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 191: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 192: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 193: \t 99.86% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 194: \t 99.86% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 195: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 196: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 197: \t 99.86% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 198: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 199: \t 99.86% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 200: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 201: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 202: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 203: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 204: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 205: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 206: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 207: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 208: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 209: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 210: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 211: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 212: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 213: \t 99.86% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 214: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 215: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 216: \t 99.86% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 217: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 218: \t 99.86% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 219: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 220: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 221: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 222: \t 99.86% - train set accuracy\n",
      "\t\t 99.00% - validation set accuracy\n",
      "\n",
      "epoch 223: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 224: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 225: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 226: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 227: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 228: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 229: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 230: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 231: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 232: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 233: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 234: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 235: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 236: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 237: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 238: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 239: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 240: \t 99.86% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 241: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 242: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 243: \t 99.86% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 244: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 245: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 246: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 247: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 248: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 249: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 250: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 251: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 252: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 253: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 254: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 255: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 256: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 257: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 258: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 259: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 260: \t 99.86% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 261: \t 99.86% - train set accuracy\n",
      "\t\t 98.93% - validation set accuracy\n",
      "\n",
      "epoch 262: \t 99.86% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 263: \t 99.86% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 264: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 265: \t 99.87% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 266: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 267: \t 99.86% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 268: \t 99.87% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 269: \t 99.86% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 270: \t 99.87% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 271: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 272: \t 99.87% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 273: \t 99.87% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 274: \t 99.87% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 275: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 276: \t 99.87% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 277: \t 99.87% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 278: \t 99.86% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 279: \t 99.86% - train set accuracy\n",
      "\t\t 98.94% - validation set accuracy\n",
      "\n",
      "epoch 280: \t 99.87% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 281: \t 99.87% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 282: \t 99.87% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 283: \t 99.87% - train set accuracy\n",
      "\t\t 98.95% - validation set accuracy\n",
      "\n",
      "epoch 284: \t 99.87% - train set accuracy\n",
      "\t\t 98.97% - validation set accuracy\n",
      "\n",
      "epoch 285: \t 99.87% - train set accuracy\n",
      "\t\t 98.96% - validation set accuracy\n",
      "\n",
      "epoch 286: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 287: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 288: \t 99.87% - train set accuracy\n",
      "\t\t 99.00% - validation set accuracy\n",
      "\n",
      "epoch 289: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 290: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 291: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 292: \t 99.87% - train set accuracy\n",
      "\t\t 99.00% - validation set accuracy\n",
      "\n",
      "epoch 293: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 294: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 295: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 296: \t 99.87% - train set accuracy\n",
      "\t\t 99.00% - validation set accuracy\n",
      "\n",
      "epoch 297: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "epoch 298: \t 99.87% - train set accuracy\n",
      "\t\t 99.01% - validation set accuracy\n",
      "\n",
      "epoch 299: \t 99.87% - train set accuracy\n",
      "\t\t 98.98% - validation set accuracy\n",
      "\n",
      "epoch 300: \t 99.87% - train set accuracy\n",
      "\t\t 98.99% - validation set accuracy\n",
      "\n",
      "Best result: 99.02%\n",
      "CPU times: user 5min 26s, sys: 47.3 s, total: 6min 14s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def getValidationAcc():\n",
    "    # Use Accuracy as the evaluation metric.\n",
    "    metric = mx.metric.Accuracy()\n",
    "    # Reset the validation data iterator.\n",
    "    val_data.reset()\n",
    "    # Loop over the validation data iterator.\n",
    "    for batch in val_data:\n",
    "        # Splits validation data into multiple slices along batch_axis\n",
    "        # and copy each slice into a context.\n",
    "        data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "        # Splits validation label into multiple slices along batch_axis\n",
    "        # and copy each slice into a context.\n",
    "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "        outputs = []\n",
    "        for x in data:\n",
    "            outputs.append(net(x))\n",
    "        # Updates internal evaluation\n",
    "        metric.update(label, outputs)\n",
    "    return metric.get()[1]\n",
    "\n",
    "validationAccToTrain = 0.99\n",
    "epochsToTrain = 300\n",
    "#               ^^--- 40 -> 300\n",
    "\n",
    "def train(net):\n",
    "    # Use Accuracy as the evaluation metric.\n",
    "    metric = mx.metric.Accuracy()\n",
    "    # Initialize the parameters with Xavier initializer\n",
    "    net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "    # Use cross entropy loss\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    # Use Adam optimizer\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.6})\n",
    "    validationAcc = None\n",
    "    maxValidationAcc = 0\n",
    "\n",
    "    for i in range(epochsToTrain):\n",
    "        # Reset the train data iterator.\n",
    "        train_data.reset()\n",
    "        # Loop over the train data iterator.\n",
    "        for batch in train_data:\n",
    "            # Splits train data into multiple slices along batch_axis\n",
    "            # and copy each slice into a context.\n",
    "            data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "            # Splits train labels into multiple slices along batch_axis\n",
    "            # and copy each slice into a context.\n",
    "            label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "            outputs = []\n",
    "            # Inside training scope\n",
    "            with ag.record():\n",
    "                for x, y in zip(data, label):\n",
    "                    z = net(x)\n",
    "                    # Computes softmax cross entropy loss.\n",
    "                    loss = softmax_cross_entropy(z, y)\n",
    "                    # Backpropogate the error for one iteration.\n",
    "                    loss.backward()\n",
    "                    outputs.append(z)\n",
    "            # Updates internal evaluation\n",
    "            metric.update(label, outputs)\n",
    "            # Make one step of parameter update. Trainer needs to know the\n",
    "            # batch size of data to normalize the gradient by 1/batch_size.\n",
    "            trainer.step(batch.data[0].shape[0])\n",
    "        # Gets the evaluation result.\n",
    "        name, acc = metric.get()\n",
    "        # Reset evaluation result to initial state.\n",
    "        metric.reset()\n",
    "        validationAcc = getValidationAcc()\n",
    "        epoch = i + 1\n",
    "        print('epoch', ('{:2.0f}:').format(epoch), '\\t', \"{:.2f}%\".format(acc * 100), '- train set accuracy'\n",
    "              '\\n\\t\\t', \"{:.2f}%\".format(validationAcc * 100), '- validation set accuracy')\n",
    "        if validationAcc > maxValidationAcc:\n",
    "            maxValidationAcc = validationAcc\n",
    "            if validationAcc >= validationAccToTrain:\n",
    "                net.export('exported/300/mnist', epoch=epoch)\n",
    "                print('saved epoch', epoch)\n",
    "        print()\n",
    "    print('Best result: {:.2f}%'.format(maxValidationAcc * 100))\n",
    "\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная достигнутая точность на проверочной части датасета составляет **99.02%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Сохранение модели на диск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели выполняется посредством функции `train` (см. раздел 1.3). Функция `train` использует глобальные переменные `validationAccToTrain` и `epochsToTrain`. Значение глобальной переменной `validationAccToTrain` соответствует точности (accuracy) на проверочной части датасета, при достижении которой и одновременно максимальной точности в ходе обучения, необходимо сохранить архитектуру и параметры модели на диск. Сохранение модели на диск выполняется посредством функции `net.export`, при этом создаются/перезаписываются два файла: **mnist-symbol.json**, содержащий информацию, определяющую архитектуру модели, и **mnist-<номер эпохи>.params**, содержащий параметры модели, полученные в ходе обучения и соответствующие эпохе <номер эпохи>. Значение глобальной переменной `epochsToTrain` соответствует количеству эпох, в течение которых необходимо проводить обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Официальный сайт mxnet: https://mxnet.apache.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
